{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a pour but de comparer les trois méthodes de clustering post-face-recognition que nous avons pu tester. Ces trois algorithmes sont : Meanshift, dbsacn et l'aglomerative clustering. Nous allons utiliser plusieurs critères de comparaison afin de conclure en présentant ce que le clustering peut proposer de mieux pour la résolution de notre problème, ainsi qu'un retour critique sur le fiabilité de cette méthode.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complexité des algorithmes : \n",
    "\n",
    "-dbscan : O(N*log(N))\n",
    "\n",
    "-Meanshift : O(N²)   \n",
    "\n",
    "-hiérarchique : O(N^3)\n",
    "\n",
    "Là où les deux premiers offrent des complexités tout à fait acceptables, l'algorithme de clustering hiérarchique s'applique difficilement à de vastes jeux de données. Cela est du au fait qu'io fonctionne de manière inverse aux deux autres: là où les deux premiers forment des clusters de plus en plus larges, celui-ci les divise sous forme d'arborescence. CE critère désigne donc dbscan comme plus utilisable que les deux autres, mais il est à noter que sur des bases de moins de 100 photos (ce sur quoi nos tests ont été effectués), il n'y a pas de différénce notable.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type d'arguments : \n",
    "\n",
    "Pour les arguments à entrer et à optimiser, l'avantage va clairement à dbscan :  en effet, celui prend en compte un nombre minimal de points demandés pour pouvoir obtenir un cluster et permet donc facilement de différencier plus facilement les outliers du cluster central, correspondant à priori au sujet dont on recherche les images. Il prend également en paramètre un nombre epsilon permettant de définir la distance maximale entre 2 plus proches voisins dans un cluster, ce qui permet de définir une marge d'erreur. Ce paramètre, bien que plus difficile à positionner est bien pratique quand on sait à quoi s'en tenir.\n",
    "\n",
    "Ensuite, Meanshift prend en paramètre une largeur de bande correspondant sur le principe au deuxième paramètre  de dbscan, même s'il ne définit pas exactement la même donnée. C'est là aussi un paramètre complexe à optimiser mais très puissant lorsqu'on peut lui donner la valeur optimale, et en accord avec notre problème.\n",
    "\n",
    "Enfin, le clustering hiérarchique s'avère très problématique sur ce point. En effet, celui prend en compte un grand nombre de paramètres secondaires, dont la forme de mémorisation, les intéractions entre points dans la mémoire vive. Mais il y a surtout deux paramètres majeurs : le nombre de clusters attendus et la métrique à utiliser pour séparer les points. Le deuxième est très intéressant à utiliser mais le second est hautement problématique compte tenu de la nature même de notre problème. En effet, notre situation est celle d'une classification binaire entre cluster principale et outliers, mais par définition, rien d'indique que les outliers peuvent être regroupés dans un même cluster, et on ne sait pas combien de lots d'outliers existent: ce paramètre rend donc l'algorithme hiérarchique inutiisable en situation réelle pour notre problème.\n",
    "\n",
    "En conclusion, l'étude des arguments pris en paramètres place le clustering hiérarchique en marge des deux autres, car là où ceux-ci semblent pouvoir s'adapter facilement à la présence et à une diversité d'outliers, le clustering hiérarchique n'a pas été conçu pour ça et son utilisation nécessite de connaître à l'avance le nombre d'outliers et surtout le nombre de groupes distincts qu'ils forment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facilité d'utilisation : \n",
    "\n",
    "sklearn.cluster.AgglomerativeClustering(n_clusters=2).fit_predict(X)\n",
    "print(clustering)\n",
    "\n",
    "\n",
    "from sklearn.cluster import MeanShift\n",
    "cluster=MeanShift()\n",
    "\n",
    "\n",
    "Meanshift et le clustering hiérarchique s'utilisent tous les deux de la même manière:  tous deux nécessitent l'importation du module sklearn, disponible en librairie de base sur Python.\n",
    "\n",
    "En revanche, dbscan nécessite d'importer un module à part (le module dbscan) qui peut faire défaut à plusieurs configurations et difficilement trouvables sur certains llogiciels d'exploitation. \n",
    "\n",
    "Dbscan est donc le moins pratique et facilement trouvable des trois, pour peu qu'on ne soit pas sur Linux notamment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facilité d'entraînement : \n",
    "\n",
    "   Sur ce point, on se retrouve à prendre le contrepied du critère concernant les arguments. En effet, le clustering hiérarchique est très facile à entraîner car on ne peut entraîner de manière générale l'argument principal du nombre de cluster désiré, compte tenu du fait qu'il n'existe que des cas particuliers et aucune généralité avec celui-ci. Ensuite, la plupart des paramètres n'ont eu aucune influence sur les essais dans notre cas. IL ne reste alors qu'à entraîner le modèle sur la distance à choisir pour effectuer les mesures. Mais celles-ci étant en nombre limité ( il n'y en a moins de 10 disponibles), il est très rapide de constater laquelle semble le plus efficace, qui s'est avérée être la distance euclidienne.\n",
    "   \n",
    "   Ensuite, Meanshift n'a lui aussi qu'un seul paramètre à optimiser, mais celui-ci requiert bien plus de temps et d'essais avant de pouvoir l'être. De nombreux essais sur des nombreuses données sont alors nécessaires.\n",
    "   \n",
    "   Enfin, dbscan, lui nécessite aussi une optimisation complexe, mais sur deux paramètres distincts, ce qui prolonge et complexifie encore plus la phase d'amélioration des paramètres de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forme des résulats : \n",
    "Cette fois, il n'y a pas vraiment de hiérarchie à tirer de nos expériences. En effet, les trois algorithmes proposent de nombreuses possibilités de visualisation. Les trois permettent de visualiser les résultats sous forme de tableau labélisé, sous forme d'arbre ou de graphique 2D. Il n'y a donc pas beaucoup à développer sur ce point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiabilité des résultats : \n",
    "    Après plusieurs tests effectués, on se retrouve avec les mesures suivantes : \n",
    "    \n",
    "    Aglomerative clustering : \n",
    "        Accuracy = 72%\n",
    "        Score F1 = 83%\n",
    "        \n",
    "    Dbscan :\n",
    "        Accuracy = 69%\n",
    "        Score F1 = 80%\n",
    "        \n",
    "    Meanshift :\n",
    "        Accuracy = 63%\n",
    "        Score F1 = 75%\n",
    "        \n",
    "        \n",
    "   NB :  accuracy=(TP+TN)/(FP+FN+TP+TN)\n",
    "    precision=TP/(TP+FP)\n",
    "    recall=TP/(TP+FN)\n",
    "    f1_score=2*(precision*recall)/(precision+recall)\n",
    "\n",
    "\n",
    "De plus, l'algorithme de clustering le plus basique qu'est k-means, avec comme but de créer 2 cluster conduit aux performances suivantes : \n",
    "     Accuracy = 71%\n",
    "     Score F1 = 83%\n",
    "     C'est à dire des performances très semblables au clustering hiérarchique\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "    \n",
    "   Comme on a pu le voir dans ce notebook, les trois algorithmes de clustering que nous avons étudiés possèdent différentes forces et faiblesses qui se compensent entre elles. En effet, l'un sera plus facile à entraîner et fournira de meilleurs résultats, un autre aura une meilleure complexité et sera plus simple d'utilisation, tandis que l'autre sera théoriquement le moins complexe et le plus adapté à notre problème mais nous fournira les résultats les moins pertinents. Il semble donc complexe de choisir un parmi les trois. De plus, commme les trois obtiennent dans les faits des scores de test inférieurs ou égaux à ceux obtenus avce l'algorithme kMeans, pourtant réputé simpliste et peu fiable, on peu considérer que l'utilisation d'un algorithme de clustering complet et permettant d'améliorer les performances de face-regognition en post-traitement n'est pas une piste convaincante car on ne peut pas faire mieux que le KMeans, qui devrait être la référence à dépasser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prise de recul et analyse des résultats : \n",
    "\n",
    "Après réflexion sur les résultats, il semble qu'on ne puisse pas réellement faire quoi que ce soit pour améliorer les performances du clustering hiérarchique ou même du Kmean, qui ne sont par nature, pas adaptés à la résolution de notre problème. Choisir à l'avance un nombre précis de clusters est en effet impossible à faire sans connaître les données avant d'y appliquer l'algorithme. De plus, de part leur complexité assez importante, surout pour le clustering hiérarchique, la possibilité de tester pour chaque utilisation un grand nombre de valeurs jusqu'à tomber sur la bonne est irréalisable, et s'adapte très mal au passage à l'échelle de notre problème.\n",
    "\n",
    "Concernant Meanshift et Dbscan, nos problèmes de résultats proviennent tout d'abord d'un soucis de normalisation des données, que nous n'avons pas faite malgré l'importance de ce procédé. C'est donc un correctif important à appliquer à nos programme. Ensuite, l'optimisation des paramètres s'est faite de manière assez grossière et peu précise. En effet, après discussion avec nos encadrants techniques, il semble que plutôt que d'effectuer des tests sur plusieurs dossiers séparément, il serait plus judicieux de tous les utiliser en même temps et d'utiliser des modules d'optmisation présents dans sikit learn. \n",
    "Il y a donc encore plusieurs choses à améliorer dans notre cheminement et sans doute dans nos résultats, car Meanshift et dbscan devraient normalement permettre d'obtenir de meilleurs résultats que cela. C'est donc cela la prochaine étape de nos travaux, en parallèle du commencement de l'étude de notre deuxième piste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
